<!-- Template from Jon Barron -->
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Yue Yang 杨樾</title>
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-111341597-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-111341597-1');
    </script>
  </head>
  <body>
    <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
      <tr>
        <td>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="65%" valign="middle">
              <name>Yue Yang (杨樾)</name><br>
              pronounced as <i>yoo-eh</i><br><br>
              Moore 103 (SIG Lab), 3300 Walnut St<br>Philadelphia, PA 19104, USA<br>
              Email: yueyang1 [at] seas.upenn.edu<br><br>
              <a href="https://scholar.google.com/citations?user=uvyYzagAAAAJ&hl=en&authuser=1">Google Scholar</a> &nbsp; / &nbsp; <a href="https://github.com/YueYANG1996">GitHub</a> &nbsp; / &nbsp; <a href="https://www.linkedin.com/in/yue-yang-4b2075174">LinkedIn</a> &nbsp; / &nbsp; <a href="https://www.youtube.com/channel/UCRV7M6KW5BZptw_aP0A-JuA">Youtube</a> &nbsp; / &nbsp; <a href="https://www.pixiv.net/users/14283763">pixiv</a> &nbsp; / &nbsp; <a href="cv.pdf">CV</a>
            </td>
            <td width="35%">
              <img src="images/swing.gif" width="100%">
            </td>
          </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <!-- About me -->
          <tr>
            <td width="100%" valign="middle">
              <heading>About me</heading><br><br>
                <p class="light">Hi! My name is Yue Yang (杨樾). I am a second-year Ph.D. student in Computer and Information Science at the University of Pennsylvania, affiliated with <a href="https://nlp.cis.upenn.edu">Penn NLP</a>. I am grateful to be advised by <a href="https://www.cis.upenn.edu/~ccb/">Prof. Chris Callison-Burch</a> and <a href="http://markyatskar.com">Prof. Mark Yatskar</a>. 
                </p>
                <p> I am interested in the intersection area of Natural Language Processing (NLP) and Computer Vision (CV), aka <a href="https://en.wikipedia.org/wiki/Multimodality">Multimodal</a>. My current research focuses on two directions to marry vision and language:
                </p>
                <ul>
                  <li>Vision helps Language: Leverage visual knowledge to alleviate the reporting bias of language models.</li>
                  <li>Language helps Vision: Language as intermediate, explict representation to improve explanability on vision tasks.</li>
                </ul>
                <img src="images/research_direction.png" width="80%">
                <p>
                  Before Penn, I was an undergrad in Mechanical Engineering at the <a href="http://www.doe.zju.edu.cn/doeen/">College of Energy Engineering</a> at Zhejiang University. I worked with <a href="https://person.zju.edu.cn/en/0010729"> Prof. Yuqi Huang</a> to study Computational Fluid Dynamics (CFD) during undergrads.
                </p>
                <p>
                  Penn initially admitted me as a master's student in <a href="https://www.grasp.upenn.edu/academics/masters-degree-program/"> Robotics</a> in 2018. Now I switch to Artificial Intelligence and temporarily farewell to the hardware (Not wholly True, I designed a sensor pack for R2D2, which students of <a href="http://artificial-intelligence-class.org/r2d2_assignments/20fall/hw0/sensor-pack-setup.html"> CIS-521</a> will use).
                </p>
            </td>
          </tr>
          </table>

          <!-- Publications & Manuscripts -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="30%" valign="middle">
                <heading>Publications</heading>
              </td>
            </tr>

            <tr>
              <td width="30%">
                <img src="images/h.gif" width="100%">
              </td>
              <td width="70%" valign="middle">
                <div class="title">
                  <a href="papers/hierarchy.pdf"><b>Show Me More Details: Discovering Hierarchies of Procedures from Semi-structured Web Data</b></a>
                </div>
                <div class="authors">
                    Shuyan Zhou, Harry Li Zhang, <strong>Yue Yang</strong>, Veronica Qing Lyu, Pengcheng Yin, Chris Callison-Burch, Graham Neubig
                </div>
                <div class="venue">
                   <i>Annual Meeting of the Association for Computational Linguistics (<b>ACL</b>)</i>, 2022
                </div>
                <div class="tags">
                  <a href="https://arxiv.org/abs/2203.07264">arxiv</a> /
                  <!-- <a href="bib/yang2021induce.bib">bibtex</a> -->
                  <a href="https://wikihow-hierarchy.github.io/?task_id=104796">website</a>
                </div>
                <div align="justify">
                  TL;DR: Procedures are inherently hierarchical. To "host a party", one may need to "clean the house", which in turn may require "putting away the clothes". We develop a simple and efficient method that links steps (e.g. "clean the house") in an article to other articles with similar intents (e.g. "how to deep lean your house"), which proceeds recursively to form the KB. 
                </div>
              </td>
            </tr>

            <tr>
              <td width="30%">
                <img src="images/IER.png" width="100%">
              </td>
              <td width="70%" valign="middle">
                <div class="title">
                  <a href="papers/IER.pdf"><b>Induce, Edit, Retrieve: Language Grounded Multimodal Schema for Instructional Video Retrieval</b></a>
                </div>
                <div class="authors">
                    <strong>Yue Yang</strong>, Joongwon Kim, Artemis Panagopoulou, Mark Yatskar and Chris Callison-Burch
                </div>
                <div class="venue">
                  <i>CVPR 2022 @ ODRUM</i>, 2022, spotlight talk
                </div>
                <div class="tags">
                  <a href="https://arxiv.org/abs/2111.09276">arxiv</a> /
                  <a href="bib/yang2021induce.bib">bibtex</a>
                </div>
                <div align="justify">
                  TL;DR: This work proposes a novel system that induces schemata from web videos and generalizes them to capture unseen tasks with the goal of improving video retrieval performance, and demonstrates that the schemata induced by the system are better than those generated by other models.
                </div>
              </td>
            </tr>

            <tr>
              <td width="30%">
                <img src="images/VGSI.png" width="100%">
              </td>
              <td width="70%" valign="middle">
                <div class="title">
                  <a href="papers/VGSI.pdf"><b>Visual Goal-Step Inference using wikiHow</b></a>
                </div>
                <div class="authors">
                    <strong>Yue Yang</strong>, Artemis Panagopoulou, Qing Lyu, Li Zhang, Mark Yatskar and Chris Callison-Burch
                </div>
                <div class="venue">
                  <i>Conference on Empirical Methods in Natural Language Processing (<b>EMNLP</b>)</i>, 2021
                </div>
                <div class="tags">
                  <a href="https://arxiv.org/abs/2104.05845">arxiv</a> / 
                  <a href="bib/yang2021visual.bib">bibtex</a> /
                  <a href="https://www.youtube.com/watch?v=V3Y_56ykG54&t=11s">talk</a> /
                  <a href="https://github.com/YueYANG1996/wikiHow-VGSI">github</a>
                </div>
                <div align="justify">
                  TL;DR: This work proposes the Visual Goal-Step Inference (VGSI) task where a model is given a textual goal and must choose a plausible step towards that goal from among four candidate images. We construct a VGSI dataset from wikiHow and show that SOTA multimodal models struggle on it. 
                </div>
              </td>
            </tr>

            <tr>
              <td width="30%">
                <img src="images/defog.gif" width="100%">
              </td>
              <td width="70%" valign="middle">
                <div class="title">
                  <a href="papers/defog.pdf"><b>Optimization of the automotive air conditioning strategy based on the study of dewing phenomenon and defogging progress</b></a>
                </div>
                <div class="authors">
                    <strong>Yue Yang</strong>, Yuqi Huang and Jisheng Zhao
                </div>
                <div class="venue">
                  <i>Applied Thermal Engineering 169 (2020): 114932.</i>
                </div>
                <div class="tags">
                  <a href="https://www.sciencedirect.com/science/article/pii/S1359431119360338">paper</a> / 
                  <a href="bib/yang2020optimization.bib">bibtex</a>
                </div>
                <div align="justify">
                  TL;DR: Numerically studied the dewing and defogging progress of a truck cabin; The external flow field was analyzed to get convective heat transfer coefficient; Effect of air velocity, temperature and humidity was considered and compared; Optimal control strategy of air conditioner was concluded based on these studies.
                </div>
              </td>
            </tr>

            <tr>
              <td width="30%">
                <img src="images/gap_flow.png" width="100%">
              </td>
              <td width="70%" valign="middle">
                <div class="title">
                  <a href="papers/gap_flow.pdf"><b>Analysis on the influence of gap flow around a tractor-trailer</b></a>
                </div>
                <div class="authors">
                    <strong>Yue Yang</strong>, Jinxing Chen, Yuqi Huang*, Jiangang Chen and Yuan Ji
                </div>
                <div class="venue">
                  <i>13th International Conference on Heat Transfer, Fluid Mechanics and Thermodynamics</i>
                </div>
                <div class="tags">
                  <a href="https://repository.up.ac.za/bitstream/handle/2263/62360/Yang_Analysis_2017.pdf?sequence=1">paper</a> / 
                  <a href="bib/yang2017analysis.bib">bibtex </a>
                </div>
                <div align="justify">
                  TL;DR: This paper aims to explore the optimum gap of tractor-trailers to reduce the aerodynamic drag by analyzing the mechanisms and laws of the flow which will decrease their energy consumption.
                </div>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Education</heading>
              <table>
                <tr>
                  <td width="85%">
                    <b>University of Pennsylvania</b>, Philadelphia, PA, USA<br>
                    <li> Ph.D. in Computer and Information Science (2020 - present)</li>
                    <li> M.S. in Robotics (2018 - 2020)</li>
                  </td>
                  <td width="15%">
                    <img src="images/penn-logo.png" width="100%" style="display: block; margin-left: auto; margin-right: auto;">
                  </td>
                </tr>
                <tr>
                  <td width="85%">
                    <b>Zhejiang University</b>, Hangzhou, China<br>
                    <li> B.E. in Mechanical Engineering (2014 - 2018)</li>
                  </td>
                  <td width="15%">
                    <img src="images/zju-logo.png" width="100%" style="display: flex; justify-content: center;">
                  </td>
                </tr>
              </table>
            </td>
          </tr>
          </table>

          <!-- Experience -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Experiences</heading>
              <table>
                <tr>
                  <td width="85%">
                    <a href="https://ai.tencent.com/ailab/nlp/en/index.html"><b>Tencent AI Lab</b></a>, Seattle, WA, USA<br>
                    <i>Research Scientist Intern</i> (May. 2022 to Sept. 2022)
                  </td>
                  <td width="15%">
                    <img src="images/tencent-logo.png" width="100%" style="display: block; margin-left: auto; margin-right: auto;">
                  </td>
                </tr>

                <tr>
                  <td width="85%">
                    <b>University of Pennsylvania & Coursera</b>, Philadelphia, PA, USA<br>
                    <i>Associate Instructor</i> (Sept. 2020 to Sept. 2022)
                  </td>
                </tr>

                 <tr>
                  <td width="85%">
                    <b>University of Pennsylvania</b>, Philadelphia, PA, USA<br>
                    <i>Research Assistant</i> (May. 2020 to present)
                  </td>
                </tr>
              </table>
            </td>
          </tr>
          </table>

          <!-- Teaching -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Teaching</heading><br><br>
              <strong>Head Teaching Assistant</strong>, <a href="https://artificial-intelligence-class.org/">CIS-521 Artificial Intelligence</a>, University of Pennsylvania<br>
              Fall2019; Fall 2020; Summer 2021; Fall 2021; Spring 2022 <br> <br>
              <strong>Teaching Assistant</strong>, <a href="http://markyatskar.com/cis530_sp2021/">CIS-530 Computational Linguistics</a>, University of Pennsylvania<br>
              Spring 2021 <br>
            </td>
          </tr>
          </table>

          <!-- Talks -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Talks</heading>
              <table>
                <tr>
                  <td width="100%">
                    <a href="https://nlp.cis.upenn.edu/clunch.html"><b>CLUNCH</b></a>, University of Pennsylvania, Philadelphia, PA, USA<br>
                    <i>Investigate Procedural Events in a Multimodal Fashion</i>, November 22, 2021. <a href="CLUNCH_talk.pdf">slides</a> 
                  </td>
                </tr>
              </table>
            </td>
          </tr>
          </table>

          <!-- Acknowledgements -->
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
              <td><br>
              <p align="right">
              <font size="2">
              Website source from <a href="https://jonbarron.info">Jon Barron</a>.
          </tr>
          </table>
        </td>
      </tr>
    </table>
  </body>
<script>'undefined'=== typeof _trfq || (window._trfq = []);'undefined'=== typeof _trfd && (window._trfd=[]),_trfd.push({'tccl.baseHost':'secureserver.net'}),_trfd.push({'ap':'cpsh-oh'},{'server':'p3plzcpnl472835'},{'id':'7914943'}) // Monitoring performance to make your website faster. If you want to opt-out, please contact web hosting support.</script><script src='https://img1.wsimg.com/tcc/tcc_l.combined.1.0.6.min.js'></script></html>
